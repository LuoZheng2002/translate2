
inspect multiple_function_checker
which is inside ast_checker

multiple function checker checks:
1. if the number of functions matches
2. passes simple_function_checker

inspect simple function checker
=> Some complicated black box


inspect ast_checker's context
which is inside _evaluate_single_ast_entry
which is inside format_sensitivity_runner and ast_file_runner

format_sensitivity_runner is inside evaluate_task
ast_file_runner is inside evaluate_task

Don't know if is_format_sensitivity(test_category)

Most probably it is none of the specified categories (ast_file_runner)

inspect evaluate_task
which is inside runner
so the eval_runner's runner does not call the model but processes its output

todo: extract logics from evaluate_task, do not use a leaderboard

generate_results might be the function that calls the LLMs

OpenAI API 



bfcl generate --model Qwen/Qwen3-0.6B --test-category multiple


Variables:
models (local hosted and api)
original/fully translated dataset/translated but keep keywords not translated
if translated, 3 way of dealing with it: 1. do nothing 2. ask to translate to English 3. use original keywords

whether add noises or not to the dataset




Fix the partially translated dataset (can be done later)

Rearrange the order of operations (noise needs to be applied last)

Implement the synonym replacement dataset

deluxe room vs. deluxe 房间



2025/11/17:

1. revise the partial translated dataset
2. add more models (qwen, llama)
3. fc models?
4. aggregate results

5. check robustness paper for methods to mitigate gaps

